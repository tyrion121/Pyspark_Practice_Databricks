print("window_function")


from pyspark.sql.window import Window
import pyspark
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("pyspark_window").getOrCreate()
 
sampleData = [("Ram", 28, "Sales", 3000),("Meena", 33, "Sales", 4600),("Robin", 40, "Sales", 4100),("Kunal", 25, "Finance", 3000),("Ram", 28, "Sales", 3000),("Srishti", 46, "Management", 3300),("Jeny", 26, "Finance", 3900),("Hitesh", 30, "Marketing", 3000),("Kailash", 29, "Marketing", 2000),("Sharad", 39, "Sales", 4100)]

columns = ["Employee_Name", "Age","Department", "Salary"]
 
df = spark.createDataFrame(data=sampleData , schema=columns)

windowPartition = Window.partitionBy("Department").orderBy("Age")

df.printSchema()  
df.show()







from pyspark.sql.functions import lag , lead 
 
df.withColumn("Lag",  lag("Salary" , 1).over(windowPartition)).show() 
df.withColumn("Lead", lead("salary", 1).over(windowPartition)).show()


from pyspark.sql.window import Window 
import pyspark
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("pyspark_window").getOrCreate()
 
sampleData = [(101, "Ram", "Biology", 80),(103, "Meena", "Social Science", 78),(104, "Robin", "Sanskrit", 58),(102, "Kunal", "Physics", 89),(101, "Ram", "Biology", 80),(106, "Srishti", "Maths", 70),(108, "Jeny", "Physics", 75),(107, "Hitesh", "Maths", 70),(109, "Kailash", "Maths", 90),(105, "Sharad","SocialScience", 84)]
columns = ["Roll_No", "Student_Name", "Subject", "Marks"]

df2 = spark.createDataFrame(data=sampleData, schema=columns)

windowPartition = Window.partitionBy("Subject").orderBy("Marks")
df2.printSchema()
df2.show()

from pyspark.sql.functions import row_number , rank , dense_rank

df2.withColumns({"row_number" : row_number().over(windowPartition) , "rank" : rank().over(windowPartition) ,"dense_rank" : dense_rank().over(windowPartition)}).show()



















 
